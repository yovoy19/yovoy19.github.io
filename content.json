{"meta":{"title":"Hexo","subtitle":"","description":"This is yovoy_blog","author":"John Doe","url":"http://example.com","root":"/"},"pages":[],"posts":[{"title":"picgo+github图床","slug":"github图床","date":"2022-07-23T05:41:31.280Z","updated":"2022-07-23T09:52:44.535Z","comments":true,"path":"2022/07/23/github图床/","link":"","permalink":"http://example.com/2022/07/23/github%E5%9B%BE%E5%BA%8A/","excerpt":"","text":"picgo工具配合gitee建立图床是大家一直普遍使用的方法。但是到我用的时候图片上传不上去，我一看已经是2022年的经验了，就重新筛选了一下，找到一个网页教程都是图示，操作起来很简单。但还是想做个笔记借鉴网页：https://bbs.huaweicloud.com/blogs/362976文章中不止有github创建图床，都可以看看 （1）获取私钥tokenSettings&#x2F;Developer settings完成后复制私钥（token），只显示一次 （2） 配置picgo配置完成，就可以使用了","categories":[],"tags":[]},{"title":"markdown语法","slug":"markdown语法","date":"2022-07-23T03:08:13.506Z","updated":"2022-07-23T06:45:19.002Z","comments":true,"path":"2022/07/23/markdown语法/","link":"","permalink":"http://example.com/2022/07/23/markdown%E8%AF%AD%E6%B3%95/","excerpt":"","text":"markdown语法为纯文本的标记语言，github博客编辑支持的编辑语言。 一、标题使用“#”区别 1234# 一级标题## 二级标题.....以此类推###### 六级标题 例如： ### 一、标题 （效果如标题一）注：markdown标准语法一般在”#”后加一个空格再写文字 二、字体加粗将文字使用两个”“包起来斜体将文字使用一个”“包起来斜体加粗将文字使用三个“*”包起来删除线要加删除线的文字用两个“~~”包起来 三、引用在文字前加“&gt;”即可，可嵌套加n个”&gt;” 四、分割线即横线，使用三个或三个以上的“-”或“*”号都可以 五、图片语法: ![图片alt]（图片地址”图片title”）图片alt:显示在图片下面的文字，相当于对图片内容的解释。图片title:图片的标题，当鼠标移到图片上时显示的内容。title可加可不加注：图片地址为图片网址也就是一个链接 六、超链接语法：超链接名title可加可不加 七、列表无序列表：”- 、+、*“都可以使用有序列表：数字加点 121. 有序列表2. 有序列表 效果： 无序列表 有序列表 有序列表列表嵌套：上一级和下一级之间隔三个空格效果：-一级无序列表 -二级无序列表1.一级有序列表 2.二级有序列表八、表格123456表头|表头|表头|-----|-----|----|内容|内容|内容|内容|内容|内容|-两边加：表示文字居中-右边加：表示文字居右 九、代码12单行代码用&quot;`&quot;包起来多行代码用三个 `包起来","categories":[],"tags":[]},{"title":"","slug":"HTML语法","date":"2022-07-23T03:03:59.779Z","updated":"2022-07-23T03:03:59.779Z","comments":true,"path":"2022/07/23/HTML语法/","link":"","permalink":"http://example.com/2022/07/23/HTML%E8%AF%AD%E6%B3%95/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"kafka Eagle运维监控","slug":"Eagle运维监控","date":"2022-06-18T04:39:20.702Z","updated":"2022-06-20T10:24:59.867Z","comments":true,"path":"2022/06/18/Eagle运维监控/","link":"","permalink":"http://example.com/2022/06/18/Eagle%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7/","excerpt":"","text":"kafka 自身并没有继承监控管理系统, 因此对 kafka 的监控管理比较不便, 好在有大量的第三方监控管理系统来使用 一、安装部署kafka Eagle####### 安装包下载地址：https://github.com/smartloli/kafka-eagle-bin/ 1.解压、安装2.配置环境变量：JAVA_HOME和KE_HOMEvi &#x2F;etc&#x2F;proflie 1234export JAVA_HOME=/usr/java/jdk1.8export PATH=$PATH:$JAVA_HOME/binexport KE_HOME=/export/server/kafka-eagleexport PATH=$PATH:$KE_HOME/bin 3.配置 KafkaEaglecd &#x2F;export&#x2F;server&#x2F;kafka-eagle&#x2F;confvi system-config.properties 123456kafka.eagle.zk.cluster.alias=cluster1cluster1.zk.list=node1:2181,node2:2181,node3:2181cluster1.kafka.eagle.broker.size=3kafka.eagle.url=jdbc:sqlite:/export/data/db/ke.db 4.启动Eagle12mkdir /export/data/db ##启动前需要手动创建/export/data/db目录/export/server/kafka-eagle/bin/ke.sh start #启动Eagle (base) [root@node1 ~]# jps5840 ResourceManager88385 KafkaEagle9203 Master6023 NodeManager87817 Kafka5193 NameNode100348 Jps2383 QuorumPeerMain5407 DataNode 二、kafka Eagle中的各项功能","categories":[],"tags":[]},{"title":"kafka API 使用方法","slug":"kafka API 使用方法","date":"2022-06-10T09:45:41.069Z","updated":"2022-06-10T11:16:48.275Z","comments":true,"path":"2022/06/10/kafka API 使用方法/","link":"","permalink":"http://example.com/2022/06/10/kafka%20API%20%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/","excerpt":"","text":"一、生产者 API一个生产者逻辑应具备以下步骤：(1)配置生产者客户端参数及创建相应的生产者实例(2)构建待发送的消息(3)发送消息(4)关闭生产者实例Kafka的Producer发送消息采用的是异步发送的方式。在消息发送的过程中，涉及到了两个线程——main线程和Sender线程，以及一个线程共享变量——RecordAccumulator。main线程将消息发送给RecordAccumulator，Sender线程不断从RecordAccumulator中拉取消息发送到Kafka broker。 1、引入 maven 依赖123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; 2、采用默认分区方式将消息散列的发送到各个分区当中123456789import org.apache.commons.lang3.RandomStringUtils;import org.apache.kafka.clients.producer.KafkaProducer;import org.apache.kafka.clients.producer.ProducerConfig;import org.apache.kafka.clients.producer.ProducerRecord;import org.apache.kafka.common.serialization.StringSerializer;import java.io.IOException;import java.util.Properties;#kafka 地址 private static final String SERVERS = &quot;node1:9092,node2:9092,node3:9092&quot;; ack 模式,取值有 0,1,-1(all) , all 是最慢但最安全的，0–&gt;不等响应就继续发（可靠性低），1–&gt;leader会写到本地日志后，然后给响应，producer拿到响应才继续发（follwer还没同步） 1234567891011121314props.put(“retries”, 3); #失败重试次数-&gt;失败会自动重试（可恢复/不可恢复）--&gt;(有可能会造成数据的乱序)props.put(“batch.size”, 10); #数据发送的批次大小提高效率/吞吐量太大会数据延迟props.put(&quot;linger.ms&quot;, 10000);#消息在缓冲区保留的时间,超过设置的值就会被提交到服务端props.put(&quot;max.request.size&quot;,10); #数据发送请求的最大缓存数props.put(“buffer.memory”, 10240); #整个 Producer 用到总内存的大小,如果缓冲区满了会提交数据到服务端#buffer.memory 要大于 batch.size,否则会报申请内存不足的错误降低阻塞的可能性props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); #key-value序列化器props.put(“value.serializer”, “org.apache.kafka.common.serialization.StringSerializer”);for (int i = 0; i &lt; 100; i++) producer.send(new ProducerRecord&lt;String,String&gt;(&quot;test&quot;, Integer.toString(i), &quot;dd:&quot;+i)); //Thread.sleep(1000000); producer.close(); &#125; &#125; 3、创建生产者实例和构建消息发送消息主要有 3 种模式：（1）发后即忘( fire-and-forget)发后即忘,它只管往 Kafka 发送,并不关心消息是否正确到达。在大多数情况下,这种发送方式没有问题;不过在某些时候(比如发生不可重试异常时)会造成消息的丢失。这种发送方式的性能最高,可靠性最差。Future send &#x3D; producer.send(rcd);（2）同步发送(sync ) 12345try &#123; producer.send(rcd).get(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; 0.8.x 前,有一个参数 producer.type&#x3D;sycn|asycn 来决定生产者的发送模式;现已失效(新版中,producer 在底层只有异步)（3）异步发送(async )回调函数会在 producer 收到 ack 时调用,为异步调用,该方法有两个参数,分别是 RecordMetadata 和Exception,如果 Exception 为 null,说明消息发送成功,如果 Exception 不为 null,说明消息发送失败。 二、消费者 API kafka的消费API支持订阅主题 (subscribe)和指定分区 (assign), 同时还可以通过 seek 对offset进行重置, 进行灵活的消费控制。一个正常的消费逻辑需要具备以下几个步骤:(1)配置消费者客户端参数(2)创建相应的消费者实例;(3)订阅主题;(4)拉取消息并消费;(5)提交消费位移 offset;(6)关闭消费者实例。 1、订阅主题123456（1）指定集合方式订阅主题consumer.subscribe(Arrays.asList(topic1)); consumer subscribe(Arrays.asList(topic2))（2）正则方式订阅主题consumer.subscribe(Pattern.compile (&quot;topic.*&quot; )); 利用正则表达式订阅主题,可实现动态订阅; 如果消费者采用的是正则表达式的方式(subscribe(Pattern))订阅, 在之后的过程中,如果有人又创建了新的主题,并且主题名字与正表达式相匹配,那么这个消费者就可以消费到新添加的主题中的消息。如果应用程序需要消费多个主题,并且可以处理不同的类型,那么这种订阅方式就很有效。 （3）assign 订阅主题1consumer.assign(Arrays.asList(new TopicPartition (&quot;tpc_1&quot; , 0),new TopicPartition(“tpc_2”,1))) ; 消费者不仅可以通过 KafkaConsumer.subscribe() 方法订阅主题,还可直接订阅某些主题的指定分区; 在 KafkaConsumer 中提供了 assign() 方法来实现这些功能：public void assign(Collection partitions)这个方法只接受参数 partitions,用来指定需要订阅的分区集合 subscribe 与 assign 的区别 通过 subscribe()方法订阅主题具有消费者自动再均衡功能 ;在多个消费者的情况下可以根据分区分配策略来自动分配各个消费者与分区的关系。当消费组的消费者增加或减少时,分区分配关系会自动调整,以实现消费负载均衡及故障自动转移。assign() 方法订阅分区时,是不具备消费者自动均衡的功能的;其实这一点从 assign()方法参数可以看出端倪,两种类型 subscribe()都有 ConsumerRebalanceListener 类型参数的方法,而 assign()方法却没有 2、取消订阅可以使用 KafkaConsumer 中的 unsubscribe()方法采取消主题的订阅,这个方法既可以取消通过subscribe( Collection)方式实现的订阅;也可以取消通过 subscribe(Pattem)方式实现的订阅,还可以取消通过 assign( Collection)方式实现的订阅。示例码如下:consumer.unsubscribe(); 如果将 subscribe(Collection )或 assign(Collection)集合参数设置为空集合,作用与 unsubscribe()方法相同,如下示例中三行代码的效果相同: 123consumer.unsubscribe(); consumer.subscribe(new ArrayList&lt;String&gt;()) ; consumer.assign(new ArrayList&lt;TopicPartition&gt;()); 3、消息的消费模式消息的消费一般有两种模式:推送模式和拉取模式。推模式是服务端主动将消息推送给消费者,而拉模式是消费者主动向服务端发起请求来拉取消息。Kafka 中的消息消费是一个不断轮询的过程,消费者所要做的就是重复地调用 poll() 方法, poll() 方法返回的是所订阅的主题(分区)上的一组消息。对于 poll () 方法而言,如果某些分区中没有可供消费的消息,那么此分区对应的消息拉取的结果就为空如果订阅的所有分区中都没有可供消费的消息,那么 poll()方法返回为空的消息集; poll () 方法具体定义如下: 1public ConsumerRecords&lt;K, V&gt; poll(final Duration timeout) 超时时间参数 timeout , 用来控制 poll() 方法的阻塞时间, 在消费者的缓冲区里没有可用数据时会发生阻塞。如果消费者程序只用来单纯拉取并消费数据,则为了提高吞吐率,可以把 timeout 设置为Long.MAX_VALUE; 12345678topic partition #这两个字段分别代表消息所属主题的名称和所在分区的编号。offsset #表示消息在所属分区的偏移量。timestamp #表示时间戳,与此对应的 timestampType 表示时间戳的类型。timestampType #有两种类型 CreateTime 和 LogAppendTime , 分别代表消息创建的时间戳和消息追加到日志的时间戳。headers #表示消息的头部内容key value #分别表示消息的键和消息的值,一般业务应用要读取的就是 value ; serializedKeySize、serializedValueSize #分别表示 key、value 经过序列化之后的大小,如果 key 为空, 则 serializedKeySize 值为 -1,同样,如果 value 为空,则 serializedValueSize 的值也会为 -1; checksum # CRC32 的校验值 (1）均衡监听器一个消费组中,一旦有消费者的增减发生,会触发消费者组的 rebalance 再均衡;如果 A 消费者消费掉的一批消息还没来得及提交 offset, 而它所负责的分区在 rebalance 中转移给了 B 消费者,则有可能发生数据的重复消费处理。此情形下,可以通过再均衡监听器做一定程度的补救; （2）指定位移消费seek()方法代码：public void seek(TopicPartiton partition,long offset)有些时候,我们需要一种更细粒度的掌控,可以让我们从特定的位移处开始拉取消息,而KafkaConsumer 中的 seek() 方法正好提供了这个功能,让我们可以追前消费或回溯消费。 （3）自动位移提交Kafka 中默认的消费位移的提交方式是自动提交,这个由消费者客户端参数 enable.auto.commit 配置, 默认值为 true 。当然这个默认的自动提交不是每消费一条消息就提交一次,而是定期提交,这个定期的周期时间由客户端参数 auto.commit.interval.ms 配置, 默认值为 5 秒, 此参数生效的前提是 enable.auto.commit 参数为 true。 在默认的方式下,消费者每隔 5 秒会将拉取到的每个分区中最大的消息位移进行提交。自动位移提交的动作是在 poll() 方法的逻辑里完成的,在每次真正向服务端发起拉取请求之前会检查是否可以进行位移提交,如果可以,那么就会提交上一次轮询的位移。Kafka 消费的编程逻辑中位移提交是一大难点,自动提交消费位移的方式非常简便,它免去了复杂的位移提交逻辑,让编码更简洁。但随之而来的是重复消费和消息丢失的问题。重复消费假设刚刚提交完一次消费位移,然后拉取一批消息进行消费,在下一次自动提交消费位移之前,消费者崩溃了,那么又得从上一次位移提交的地方重新开始消费,这样便发生了重复消费的现象(对于再均衡的情况同样适用)。我们可以通过减小位移提交的时间间隔来减小重复消息的窗口大小,但这样并不能避免重复消费的发送,而且也会使位移提交更加频繁。丢失消息按照一般思维逻辑而言,自动提交是延时提交,重复消费可以理解,那么消息丢失又是在什么情形下会发生的呢?我们来看下图中的情形: 拉取线程不断地拉取消息并存入本地缓存, 比如在 BlockingQueue 中, 另一个处理线程从缓存中读取消息并进行相应的逻辑处理。设目前进行到了第 y+l 次拉取,以及第 m 次位移提交的时候,也就是x+6 之前的位移己经确认提交了, 处理线程却还正在处理 x+3 的消息; 此时如果处理线程发生了异常, 待其恢复之后会从第 m 次位移提交处,也就是 x+6 的位置开始拉取消息,那么 x+3 至 x+6 之间的消息就没有得到相应的处理,这样便发生消息丢失的现象。 （4）手动位移提交12enable.auto.commit 配置为 fals ；props.put(ConsumerConf.ENABLE_AUTO_COMMIT_CONFIG, false); 手动提交可以细分为同步提交和异步提交,对应于 KafkaConsumer 中的 commitSync()和commitAsync()两种类型的方法异步提交方式 1234public void commitAsync()public void commitAsync(OffsetCommitCallback ca11back)public void commitAsync(final Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, OffsetCommitCallback callback) commitSync()方法相反,异步提交的方式( commitAsync())在执行的时候消费者线程不会被阻塞;可能在提交消费位移的结果还未返回之前就开始了新一次的拉取操 。异步提交以便消费者的性能得到一定的增强。 commitAsync 方法有一个不同的重载方法自动位移提交的方式在正常情况下不会发生消息丢失或重复消费的现象, 但是在编程的世界里异常无可避免; 同时, 自动位移提交也无法做到精确的位移管理。 在 Kafka 中还提供了手动位移提交的方式, 这样可以使得开发人员对消费位移的管理控制更加灵活。很多时候并不是说拉取到消息就算消费完成,而是需要将消息写入数据库、写入本地缓存,或者是更加复杂的业务处理。在这些场景下,所有的业务处理完成才能认为消息被成功消费; 手动的提交方式可以让开发人员根据程序的逻辑在合适的地方进行位移提交。 开启手动提交功能的前提是消费者客户端参数。 1public void commitSync(final Map&lt;TopicPartition,OffsetAndMetadata&gt; offsets) 对于采用 commitSync()的无参方法,它提交消费位移的频率和拉取批次消息、处理批次消息的频率是一样的, 如果想寻求更细粒度的、 更精准的提交, 那么就需要使用 commitSync()的另一个有参方法, 具体定义 1234567891011121314151617其他参数fetch.min.bytes=1B #一次拉取的最小字节数fetch.max.bytes=50M #一次拉取的最大数据量fetch.max.wait.ms=500ms #拉取时的最大等待时长max.partition.fetch.bytes = 1MB #每个分区一次拉取的最大数据量max.poll.records=500 #一次拉取的最大条数connections.max.idle.ms=540000ms #网络连接的最大闲置时长request.timeout.ms=30000ms #一次请求等待响应的最大超时时间consumer #等待请求响应的最长时间metadata.max.age.ms=300000 #元数据在限定时间内没有进行更新,则会被强制更新reconnect.backoff.ms=50ms #尝试重新连接指定主机之前的退避时间retry.backoff.ms=100ms #尝试重新拉取数据的重试间隔isolation.level=read_uncommitted #隔离级别! 决定消费者能读到什么样的数据read_uncommitted: #可以消费到 LSO(LastStableOffset)位置; read_committed: #可以消费到 HW(High Watermark)位置max.poll.interval.ms #超过时限没有发起 poll 操作,则消费组认为该消费者已离开消费组enable.auto.commit=true #开启消费位移的自动提交auto.commit.interval.ms=5000 #自动提交消费位移的时间间隔 代码实例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879package ccjzrgzn.kafka; import org.apache.kafka.clients.consumer.ConsumerConfig; import org.apache.kafka.clients.consumer.ConsumerRecord; import org.apache.kafka.clients.consumer.ConsumerRecords; import org.apache.kafka.clients.consumer.KafkaConsumer; import org.apache.kafka.common.serialization.StringDeserializer; import java.time.Duration; import java.util.Arrays; import java.util.Properties; import java.util.concurrent.atomic.AtomicBoolean;public class ConsumerDemo &#123; private static final String SERVERS = &quot;node1:9092,node2:9092,node3:9092&quot;; public static void main(String[] args) throws InterruptedException &#123; //定义一个AtomicBoolean类型的isRunning来控制消费者拉取消息 AtomicBoolean isRunning = new AtomicBoolean(true); //1.参数配置 Properties props = new Properties(); //key的反序列化器 props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); //value的反序列化器 props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName()); //服务器地址 props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,SERVERS); //设置自动读取的起始offset（偏移量），值可以是：earliest，latest，none props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG,&quot;earliest&quot;); //设置自动提交offset（偏移量） props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG,true); //设置消费者组 props.put(ConsumerConfig.GROUP_ID_CONFIG,&quot;b1&quot;); //2.构建consumer实例 KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(props); //3.订阅主题 consumer.subscribe(Arrays.asList(&quot;tpc_1&quot;)); //4.拉取消息 Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; while (isRunning.get())&#123; ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(Long.MAX_VALUE)); for (ConsumerRecord&lt;String, String&gt; record : records) &#123; //do some process做一些处理 System.out.println(record.key()+&quot;,&quot; +record.value()+&quot;,&quot; +record.topic()+&quot;,&quot; +record.partition()+&quot;,&quot; +record.offset()); System.out.println(&quot;-------------------------分割线--------------------------&quot;); &#125; &#125; &#125; &#125;); thread.start(); //主线程可以去休眠60s Thread.sleep(60000); //修改isRunning的值为false isRunning.set(false); //5.关闭consumer实例 consumer.close(); &#125;&#125; kafka的消费API支持订阅主题(subscribe)和指定分区(assign), 同时还可以通过seek对offset进行重置, 进行灵活的消费控制.提交offset的时候, 可以用consumer.commitSync()提交所有分区当前poll后的offset, 也可以用consumer.commitSync(offsets)来手动指定提交的offset, 当然也可以将offset存储在外部数据源, 配合seek实现 “精准一次” 的消费语义. 三、Topic管理 APIKafka官方提供了两个脚本来管理topic，包括topic的增删改查。其中kafka-topics.sh负责topic的创建与删除；kafka-configs.sh脚本负责topic的修改和查询。一般情况下,使用 kafka-topic.sh 来管理主题。当用到管理类功能时程序需要调用 API 方式去实现。调用 API方式实现管理主要利用 KafkaAdminClient 工具类。 创建主题:CreateTopicsResult createTopics(CollectionnewTopics删除主题:DeleteTopicsResult deleteTopics(Collectiontopics)。列出所有可用的主题:ListTopicsResultlistTopics)。查看主题的信息:DescribeTopicsResult describeTopics(CollectiontopicNames). 查询配置信息:DescribeConfigsResult describeConfiss(Collectionresources).修改配置信息:AlterConfigsResultalterConfigs(Mapconfigs)。增加分区:CreatePartitionsResult createPartitions(Map&lt;String.NewPartitions&gt;newPartitions) 代码实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package ccjzrgzn.kafka;import org.apache.kafka.clients.admin.*;import org.apache.kafka.common.KafkaFuture;import java.util.*;import java.util.concurrent.ExecutionException;public class KafkaAdminDemo &#123; private static final String SERVERS = &quot;node1:9092,node2:9092,node3:9092&quot;; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; Properties props = new Properties(); props.setProperty(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, SERVERS); //1.构建一个管理客户端的对象 AdminClient adminClient = KafkaAdminClient.create(props); //2.列出集群中的主题信息 ListTopicsResult listTopicsResult = adminClient.listTopics(); KafkaFuture&lt;Set&lt;String&gt;&gt; names = listTopicsResult.names(); Set&lt;String&gt; topicNames = names.get(); System.out.println(topicNames); //3.查看一个topic的具体信息 DescribeTopicsResult tpc_1 = adminClient.describeTopics(Arrays.asList(&quot;tpc_10&quot;)); KafkaFuture&lt;Map&lt;String, TopicDescription&gt;&gt; future = tpc_1.all(); Map&lt;String, TopicDescription&gt; stringTopicDescriptionMap = future.get();//get()会阻塞直到拿到返回值 Set&lt;Map.Entry&lt;String, TopicDescription&gt;&gt; entries = stringTopicDescriptionMap.entrySet(); for (Map.Entry&lt;String, TopicDescription&gt; entry : entries) &#123; System.out.println(entry.getKey()); TopicDescription desc = entry.getValue(); System.out.println(desc.name()+&quot;,&quot;+desc.partitions()); System.out.println(&quot;--------------------------&quot;); &#125;//4.创建topic HashMap&lt;Integer, List&lt;Integer&gt;&gt; patitions = new HashMap&lt;&gt;(); patitions.put(0,Arrays.asList(0,2)); patitions.put(1,Arrays.asList(1,2)); patitions.put(2,Arrays.asList(0,1)); NewTopic tpc_10 = new NewTopic(&quot;tpc_10&quot;,patitions);// NewTopic tpc_10 = new NewTopic(&quot;tpc_10&quot;,2,(short) 3); adminClient.createTopics(Arrays.asList(tpc_10)); adminClient.close(); &#125;&#125;","categories":[],"tags":[]},{"title":"kafka命令行操作","slug":"kafka命令行操作","date":"2022-06-10T09:44:48.371Z","updated":"2022-06-10T10:08:39.088Z","comments":true,"path":"2022/06/10/kafka命令行操作/","link":"","permalink":"http://example.com/2022/06/10/kafka%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C/","excerpt":"","text":"Kafka 中提供了许多命令行工具用于管理集群的变更。 kafka-configs.sh 用于配置管理 kafka-console-consumer.sh 用于消费消息 kafka-console-producer.sh 用于生产消息 kafka-consumer-perf-test.sh 用于测试消费性能 kafka-topics.sh 用于管理主题 kafka-dump-log.sh 用于查看日志内容 kafka-server-stop.sh 用于关闭Kafka 服务 kafka-preferred-replica-election.sh 用于优先副本的选举 kafka-server-start.sh 用于启动Kafka服务 kafka-producer-perf-test.sh 用于测试生产性能 kafka-reassign-partitions.sh 查看帮助 1、查看topic 1kafka-topic.sh --list --zookeeper node1:2181 __consumer_offsets 2、创建topic（1）.不指定分区创建topic 12./kafka-topics.sh --zookeeper node1:2181,node2:2181,node3:2181 --create --replication-factor 3 --partitions 3 --topic test （2）手动指定副本的存储位置 12345bin/kafka-topics.sh --create --topic tpc_1 --zookeeper node1:2181 --replica-assignment 0:1,1:2--replication-factor #副本数量--partitions #分区数量--topic #topic 名称 注：该方式下,命令会自动判断所要创建的 topic 的分区数及副本数3、删除 topic 1bin/kafka-topics.sh --delete --topic tpc_6 --zookeeper node1：2181 （异步线程去删除）删除 topic,需要一个参数处于启用状态: delete.topic.enable &#x3D; true,否则删不掉使用 kafka-topics .sh 脚本删除主题的行为本质上只是在 ZooKeeper 中的&#x2F;admin&#x2F;delete_topics 路径下 建一个与待删除主题同名的节点,以标记该主题为待删除的状态。与创建主题相同的是,真正删除主题的动作也是由 Kafka 的控制器负责完成的。4、查看 topic（1）列出当前系统中的所有 topic 1bin/kafka-topics.sh --zookeeper node1:2181,node2:2181,node3:2181 –list （2）查看 topic 详细信息 12bin/kafka-topics.sh --create --topic tpc_1 --zookeeper node1:2181 --replica-assignment 0:1,1:2bin/kafka-topics.sh --describe --topic tpc_1 --zookeper node1:2181 可以看到topic 的分区数量, 以及每个分区的副本数量,以及每个副本所在的 broker 节点,以及每个分区的 leader 副本所在 broker 节点,以及每个分区的 ISR 副本列表; ISR: in sync replicas #同步副本(当然也包含 leader 自身)OSR:out of sync replicas #失去同步的副本(数据与 leader 之间的差距超过配置的阈值)5、增加分区数Kafka 只支持增加分区,不支持减少分区，原因是减少分区,代价太大(数据的转移,日志段拼接合并) 1bin/kafka-topics.sh --alter --topic tpc_1 --partitions 3 --zookeeper node1:2181 6、动态配置 topic 参数通过管理命令,可以为已创建的 topic 增加、修改、删除 topic level 参数。（1）添加、修改配置参数（开启压缩发送传输种提高kafka消息吞吐量的有效办法(‘gzip’, ‘snappy’, ‘lz4’, ‘zstd’)） 12bin/kafka-configs.sh --zookeeper node1:2181 --entity-type topics --entity-name tpc_1 --alter --add-config compression.type=gzip （2）删除配置参数 12bin/kafka-configs.sh --zookeeper node1:2181 --entity-type topics --entity-name tpc_1 --alter --delete-config compression.type 7、生产者写入数据、消费者拉取数据（1）生产者：kafka-console-producer 12bin/kafka-console-producer.sh --broker-list node1:9092, node2:9092, node3:9092 --topic tpc_1 （2）消费者：kafka-console-producer 123456#从头开始bin/kafka-console-consumer.sh --bootstrap-server node1:9092, node2:9092, node1:9092 --topic tpc_1 --from-beginning# 指定要消费的分区,和要消费的起始 offset bin/kafka-console-consumer.sh --bootstrap-server node1:9092,node2:9092,node3:9092 --topic tcp_1 --offset 2 --partition 0","categories":[],"tags":[]},{"title":"kafka环境配置","slug":"kafka环境配置","date":"2022-06-10T06:05:42.774Z","updated":"2022-06-10T09:43:46.152Z","comments":true,"path":"2022/06/10/kafka环境配置/","link":"","permalink":"http://example.com/2022/06/10/kafka%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","excerpt":"","text":"Kafka 是一种分布式的，基于发布 &#x2F; 订阅的消息系统。主要设计目标如下： （1）以时间复杂度为 O(1) 的方式提供消息持久化能力，即使对 TB 级以上数据也能保证常数时间复杂度的访问性能。（2）高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒 100K 条以上消息的传输。（3）支持 Kafka Server 间的消息分区，及分布式消费，同时保证每个 Partition 内的消息顺序传输。（4）同时支持离线数据处理和实时数据处理。Scale out：支持在线水平扩展 一、基础配置1.导入三台已配置好zookeeper组件以及免密互通的虚拟机 二、安装配置kafka2.在master主机上，上传安装包，解压 12tar -zxvf kafka_2.11-2.0.0.tgzln -s kafka_2.11-2.0.0/ kafka #建立软连接 3.修改配置文件 server.properties 1vi/export/server/kafka/config/server.properties 修改内容如下： 12#listeners=PLAINTEXT://:9092 取消注释，内容改为：listeners=PLAINTEXT://master:9092 #PLAINTEXT为通信使用明文（加密ssl） 12log.dirs=/tmp/kafka-logs为默认日志文件存储的位置改为log.dirs=/export/server/data/kafka-logs 12345#数据安全性（持久化之前先放到缓存上，从缓存刷到磁盘上）interval.messages interval.ms168/24=7，1073741824/1024=1GB #数据保留策略300000ms = 300s = 5min #超过了删掉（最后修改时间还是创建时间--&gt;日志段中最晚的一条消息，维护这个最大的时间戳--&gt;用户无法 干预） 1234#指定zookeeper集群地址zookeeper.connect=localhost:2181 修改为zookeeper.connect=master:2181,slave1:2181,slave2:2181group.initial.rebalance.delay.ms=0 修改为 group.initial.rebalance.delay.ms=3000 4.分发配置文件给node2，node3分发kafka 123cd /export/server/ scp -r /export/server/kafka_2.11-2.0.0/ node2:$PWD scp -r /export/server/kafka_2.11-2.0.0/ node3:$PWD 5.配置环境变量（三台） 123#KAFKA_HOMEexport KAFKA_HOME=/export/server/kafkaexport PATH=$PATH:$KAFKA_HOME/bin 6.node2,node3修改配置文件server.properties： 123vi server.propertieslisteners=PLAINTEXT://master:9092修改listeners=PLAINTEXT://node2:9092 同理node3 同样操作 7.验证kafka 123（基于zookeeper启动）kafka-server-start.sh -daemon /export/ #启动kafkakafka-server-stop.sh stop #关闭kafka","categories":[],"tags":[]},{"title":"Spark HA & Yarn配置","slug":"Spark HA & Yarn配置","date":"2022-05-24T15:26:28.126Z","updated":"2022-05-24T15:55:29.352Z","comments":true,"path":"2022/05/24/Spark HA & Yarn配置/","link":"","permalink":"http://example.com/2022/05/24/Spark%20HA%20&%20Yarn%E9%85%8D%E7%BD%AE/","excerpt":"","text":"Spark支持ZooKeeper来实现 HA,on yarn:运行在 yarn 资源管理器框架之上，由 yarn 负责资源管理，Spark 负责任务调度和计算 一、Spark（HA）（1）修改spark-env.sh配置文件删除SPARK_MASTER_HOST=node1不固定master节点增加内容： 1234567## 设置历史服务器# 配置的意思是 将spark程序运行的历史日志 存到hdfs的/sparklog文件夹中SPARK_HISTORY_OPTS=&quot;-Dspark.history.fs.logDirectory=hdfs://node1:8020/sparklog/ -Dspark.history.fs.cleaner.enabled=true&quot;SPARK_DAEMON_JAVA_OPTS=&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=node1:2181,node2:2181,node3:2181 -Dspark.deploy.zookeeper.dir=/spark-ha&quot;# spark.deploy.recoveryMode 指定HA模式 基于Zookeeper实现# 指定Zookeeper的连接地址# 指定在Zookeeper中注册临时节点的路径 (2)将spark-env.sh分发到node2和node3 12scp spark-env.sh node2:/export/server/spark/conf/scp spark-env.sh node3:/export/server/spark/conf (3)启动集群1.关闭当前StandAlone集群 1sbin/stop-all.sh 2.在node1上 启动一个master 和全部worker 12cd /export/server/spark/sbin/start-all.shsbin/start-all.sh 3.在node2上启动一个备用的master进程 1sbin/start-master.sh (base) [root@node1 ~]# jps3985 Worker3749 Master4300 Jps2383 QuorumPeerMain4.查看状态：①node1:8080端口状态为ALIVE在node2上是备用master，当node1启用master时node2状态为standby(8080端口可能会发生顺延)5.关闭node1的master进程，node2master启用其状态切换为ALIVE(4)测试：提交一个spark任务到当前ALIVEmaster上: 12bin/spark-submit --master spark://node1:7077 /export/server/spark/examples/src/main/python/pi.py 1000 提交后，将ALIVEmaster kill掉，不会影响程序当新的master（即使用node2备用master）接收集群后, 程序继续运行, 正常得到结果HA模式下，主备切换不会影响正在运行的程序 二、Spark(Yarn)yarn-cluster：适用于生产环境yarn-client：适用于交互、调试，希望立即看到app的输出在spark-env.sh 以及 环境变量配置文件中即可(1)连接到YARN中 1bin/pyspark --master yarn --deploy-mode client|cluster 注意: 交互式环境 pyspark 和 spark-shell 无法运行 cluster模式(2)client 模式测试测试yarn提交spark任务 123/export/server/spark/bin/spark-submit --master yarn --deploy-mode cluster \\ --driver-memory 512m --executor-memory 512m --num-executors 3 --total-executor-cores 3 \\/export/server/spark/examples/src/main/python/pi.py 3 (3)cluster 模式测试 123/export/server/spark/bin/spark-submit --master yarn --deploy-mode cluster \\--driver-memory 512m --executor-memory 512m --num-executors 3 --total-executor-cores 3 \\/export/server/spark/examples/src/main/python/pi.py 3 (4)通过web UI查看任务运行状态http://master:8080/","categories":[],"tags":[]},{"title":"spark local & stand-alone配置","slug":"Spark local& stand-alone配置","date":"2022-05-24T10:27:19.339Z","updated":"2022-05-24T16:00:31.437Z","comments":true,"path":"2022/05/24/Spark local& stand-alone配置/","link":"","permalink":"http://example.com/2022/05/24/Spark%20local&%20stand-alone%E9%85%8D%E7%BD%AE/","excerpt":"","text":"Spark 有多种运行模式， Spark 支持本地运行模式（Local 模式）、独立运行模式（Standalone 模式）、YARN（Yet Another Resource Negotiator）local(本地模式)：常用于本地开发测试，本地还分为local单线程和local-cluster多线程;standalone(集群模式)：典型的Mater&#x2F;slave模式，不过也能看出Master是有单点故障的；Spark支持ZooKeeper来实现 HA 一、spark（local）###（一）Anaconda On Linux安装（单机服务器脚本安装）（1）上传解压安装包，安装 1sh./Anaconda3-2021.05-Linux-x86_64.sh 一次回车+5次空格Do you accept the license terms? [yes&#x2F;no]&gt;&gt;&gt; yesAnaconda3 will now be installed into this location:&#x2F;root&#x2F;anaconda3 - Press ENTER to confirm the location - Press CTRL -C to abort the installation - Or specify a different location below[&#x2F;root&#x2F;anaconda3]&gt;&gt;&gt; &#x2F;export&#x2F;server&#x2F;anaconda3 (Anaconda3安装位置，推荐在&#x2F;export&#x2F;server&#x2F;anaconda3)by running conda init? [yes&#x2F;no] &gt;&gt;&gt; yes （是否初始化，输yes）安装完成，重新连接 (base) [root@node1 ~]#出现bash安装完成（2）创建虚拟环境 123456#pyspark 基于 python3.8 conda create -n pyspark python=3.8# 切换到虚拟环境内conda activate pyspark# 在虚拟环境内安装包pip install pyhive pyspark jieba -i https://pypi.tuna.tsinghua.edu.cn/simple (pyspark) [root@node1 ~]#(3)安装spark1.上传，解压，压缩包 1tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C /export/server/ 2.建立软连接 1ln -s /export/server/spark-3.2.0-bin-hadoop3.2 /export/server/spark 3.添加环境变量 1234567vi /etc/profile#SPARK_HOMEexport SPARK_HOME=/export/server/spark#HADOOP_CONF_DIRexport HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop#PYSPARK_PYTHONexport PYSPARK_PYTHON=/export/server/anaconda3/envs/pyspark/bin/python 重新加载环境变量： 1source /etc/profile 4.进入pyspark界面 12cd /export/server/anaconda3/envs/pyspark/bin/ ./pyspark (base) [root@node1 bin]# .&#x2F;pysparkPython 3.8.13 (default, Mar 28 2022, 11:38:47)[GCC 7.5.0] :: Anaconda, Inc. on linuxType “help”, “copyright”, “credits” or “license” for more information.22&#x2F;05&#x2F;24 19:26:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicableWelcome to ____ __ &#x2F; &#x2F; ___ _&#x2F; &#x2F; \\ / _ / _ &#96;&#x2F; _&#x2F; ‘&#x2F; &#x2F;_ &#x2F; .&#x2F;_,&#x2F;&#x2F; &#x2F;&#x2F;_\\ version 3.2.0 &#x2F;&#x2F; Using Python version 3.8.13 (default, Mar 28 2022 11:38:47)Spark context Web UI available at http://node1:4040Spark context available as ‘sc’ (master &#x3D; local[*], app id &#x3D; local-1653391619858).SparkSession available as ‘spark’. 5.浏览器访问验证 http://master:4040/ 二、Spark(stand-alone)Standalone模式(集群) Spark中的各个角色以独立进程的形式存在,并组成Spark集群环境（1）master 节点修改配置文件进入文件路径 1cd /export/server/spark/conf 1.将文件 workers.template 改名为 workers，并配置文件内容将里面的localhost删除， 123456mv workers.template workersvi workers删除localhost 改为node1node2node3 2.将文件 spark-env.sh.template 改名为 spark-env.sh，并配置相关内容 12mv spark-env.sh.template spark-env.shvi spark-env.sh 添加以下配置 123456789101112131415161718## 指定spark老大Master的IP和提交任务的通信端口# 告知Spark的master运行在哪个机器上#export SPARK_MASTER_HOST=node1# 告知sparkmaster的通讯端口export SPARK_MASTER_PORT=7077# 告知spark master的 webui端口SPARK_MASTER_WEBUI_PORT=8080# worker cpu可用核数SPARK_WORKER_CORES=1# worker可用内存SPARK_WORKER_MEMORY=1g# worker的工作通讯地址SPARK_WORKER_PORT=7078# worker的 webui地址SPARK_WORKER_WEBUI_PORT=8081 3.修改spark-defaults.conf 123456789vi spark-defaults.conf# Example:# spark.master spark://master:7077spark.eventLog.enabled truespark.eventLog.dir hdfs://node1:8020/sparklog/# spark.serializer org.apache.spark.serializer.KryoSerializer# spark.driver.memory 5g# spark.executor.extraJavaOptions -XX:+PrintGCDetails -Dkey=value -Dnumbers=&quot;one two three&quot;spark.eventLog.compress true 4.在HDFS上创建程序运行历史记录存放的文件夹 12hadoop fs -mkdir /sparkloghadoop fs -chmod 777 /sparklog 5.配置 log4j.properties 文件 1log4j.rootCategory=INFO, console 改为 log4j.rootCategory=WARN, console 即将INFO 改为 WARN 目的：输出日志, 设置级别为WARN 只输出警告和错误日志，INFO 则为输出所有信息，多数为无用信息6.master 节点分发 spark 安装文件夹 到 node2 和 node3 上 12scp -r /export/server/spark-3.2.0-bin-hadoop3.2/ node2:$PWDscp -r /export/server/spark-3.2.0-bin-hadoop3.2/ node3:$PWD (2)在node2 和 node3 上做软连接 1ln -s /export/server/sprk-3.2.0-bin-hadoop3.2 /export/server/spark (3)验证重新加载环境变量，启动Spark的Master和Worker进程 123source /etc/profilecd /export/server/spark/sbin./start-history-server.sh (base) [root@node1 ~]# jps3985 Worker3749 Master4300 Jps2383 QuorumPeerMain(4)访问 WebUI界面: http:&#x2F;&#x2F;主节点ip:8080&#x2F;默认端口master我们设置到了8080如果端口被占用, 会顺延到8081 …;8082… 8083… 直到申请到端口为止可以在日志中查看, 具体顺延到哪个端口上: 1Service &#x27;MasterUI&#x27; could not bind on port 8080. Attempting port 8081. 1.连接到standalone集群测试代码 123cd /export/server/anaconda3/envs/pyspark/bin/ ./pysparksc.parallelize(Array(1,2,3,4,5)).map(x=&gt; x + 1).collect() sc.parallelize(Array(1,2,3,4,5)).map(x&#x3D;&gt; x + 1).collect()[2,3,4,5,6]查看历史服务器 12bin/spark-submit --master spark://node1:7077 /export/server/spark/examples/src/main/python/pi.py 100 历史服务器的默认端口是: 18080http:&#x2F;&#x2F;主节点ip:18080&#x2F;","categories":[],"tags":[]},{"title":"spark基础环境配置","slug":"Spark基础环境","date":"2022-05-21T09:45:28.537Z","updated":"2022-05-24T13:29:37.152Z","comments":true,"path":"2022/05/21/Spark基础环境/","link":"","permalink":"http://example.com/2022/05/21/Spark%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83/","excerpt":"","text":"spark 是一种与 Hadoop 相似的开源集群计算环境，但是两者之间还存在一些不同之处，这些有用的不同之处使 Spark 在某些工作负载方面表现得更加优越，换句话说，Spark 启用了内存分布数据集，除了能够提供交互式查询外，它还可以优化迭代工作负载 一、基础环境1.导入三台虚拟机，配置如下 主机名 node1 node2 node3 IP 192.168.231.151 192.168.231.152 192.168.231.153 用户名、密码 root&#x2F;123456 root&#x2F;123456 root&#x2F;123456 2.集群角色规划 服务器 运行角色 node1.itcast.cn Namenode(主角色)，Datanode(从角色)，Resourcemanager(主角色)，Nodemanager(从角色)，master，follower，worker，QuorumPeerMain,sparksubmit node2.itcast.cn Secondarynamenode(主角色辅助角色)，datanode(从角色)，Nodemanager(从角色)，worker，leader node2.itcast.cn Datanode(从角色)，nodemanager(从角色)，worker，follower （一）主机hosts映射（三台）：1234567(base) [root@node1 ~]# vi /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.231.151 node1 node1.itcast.cn192.168.231.152 node2 node1.itcast.cn192.168.231.153 node3 node1.itcast.cn More info: Writing（1）关闭防火墙 1systemctl status firewalld.service 如下：[root@node1 ~]# systemctl status firewalld.service● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;firewalld.service; disabled; vendor preset: enabled) Active: inactive (dead) Docs: man:firewalld(1)More info: Server（2）同步时间 1ntpdate ntp5.aliyun.com [root@node1 ~]# ntpdate ntp5.aliyun.com24 May 15:40:06 ntpdate[6487]: step time server 203.107.6.88 offset 0.770984 secYou have new mail in &#x2F;var&#x2F;spool&#x2F;mail&#x2F;root (二)配置ssh免密登录（三台）node1免密登录2、3 1ssh-keygen -t rsa(4次回车) [root@node1 ~]# ssh-keygen -t rsaGenerating public&#x2F;private rsa key pair.Enter file in which to save the key (&#x2F;root&#x2F;.ssh&#x2F;id_rsa):&#x2F;root&#x2F;.ssh&#x2F;id_rsa already exists.Overwrite (y&#x2F;n)? yEnter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in &#x2F;root&#x2F;.ssh&#x2F;id_rsa.Your public key has been saved in &#x2F;root&#x2F;.ssh&#x2F;id_rsa.pub.The key fingerprint is:SHA256:Um11dr+jE0C5kCbEYyoKqZpQBqMuqSF4Pq6WpnRGtg4 &#114;&#x6f;&#111;&#116;&#64;&#110;&#111;&#100;&#x65;&#x31;&#46;&#105;&#x74;&#x63;&#97;&#115;&#116;&#x2e;&#99;&#x6e;The key’s randomart image is:+—[RSA 2048]—-+| o. ..o o .||o &#x3D; &#x3D;.o o ..||.+ o &#x3D; +.. .||+ o. . . . .. .||&#x3D;+.o. . S . o ||Oo+ . . o .||*E.+ o ||&#x3D;+B . ||*o.o |+—-[SHA256]—–+You have new mail in &#x2F;var&#x2F;spool&#x2F;mail&#x2F;root 12ssh-copy-id node2 （输入node2密码）ssh-copy-id node3 （node3密码） (base) [root@node1 ~]# ssh-copy-id node2&#x2F;usr&#x2F;bin&#x2F;ssh-copy-id: INFO: Source of key(s) to be installed: “&#x2F;root&#x2F;.ssh&#x2F;id_rsa.pub”&#x2F;usr&#x2F;bin&#x2F;ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed&#x2F;usr&#x2F;bin&#x2F;ssh-copy-id: INFO: 1 key(s) remain to be installed – if you are prompted now it is to install the new keysroot@node2’s password: (输入node2密码) Number of key(s) added: 1 Now try logging into the machine, with: “ssh ‘node2’”and check to make sure that only the key(s) you wanted were added. You have new mail in &#x2F;var&#x2F;spool&#x2F;mail&#x2F;root验证： 12ssh node2ssh node3 (base) [root@node1 ~]# ssh node2Last login: Fri May 13 08:33:21 2022 from 192.168.231.1 同理，node2，node3也一样。 二、安装配置JDK(1)编译环境软件安装目录 1mkdir -p /export/servers (2)上传、解压、安装jdk解压至&#x2F;export&#x2F;severs、 1tar -zxvf /export/servers/jdk-8u241-linux-x64.tar.gr -C /export/servers/ JDK安装目录重命名为jdk 1mv /export/servers/jdk1.8.0_241/ jdk More info: Generating(3)配置环境变量添加jdk配置： 12345vi /etc/profile#JDKexport JAVA_HOME=/export/server/jdk1.8.0_241export PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar (4)重新加载环境变量并验证： 12source /etc/profilejava -version [root@node1 ~]# java -versionjava version “1.8.0_241”Java(TM) SE Runtime Environment (build 1.8.0_241-b07)Java HotSpot(TM) 64-Bit Server VM (build 25.241-b07, mixed mode)(5)分发JDK相关文件到node2，node31.jdk相关文件： 12scp -r /export/servers/jdk1.8.0_171/ root@node2:/export/servers/ scp -r /export/servers/jdk1.8.0_171/ root@node3:/export/servers/ 2.系统环境变量： 12scp -r /etc/profile root@node2:/etc/profile scp -r /etc/profile root@node3:/etc/profile 3.分别在node2、3重新使环境变量生效 1source /etc/profile 三、Hadoop集群的安装和配置(1)上传 Hadoop 安装包并解压 1tar zxvf hadoop-3.3.0-Centos7-64-with-snappy.tar.gz (2)修改配置文件 1cd /export/server/hadoop-3.3.0/etc/hadoop 1.hadoop-env.sh 12345678export JAVA_HOME=/export/server/jdk1.8.0_241#Hadoop各个组件启动运行身份export HDFS_NAMENODE_USER=rootexport HDFS_DATANODE_USER=rootexport HDFS_SECONDARYNAMENODE_USER=rootexport YARN_RESOURCEMANAGER_USER=rootexport YARN_NODEMANAGER_USER=root 2.core-site.xml 1234567891011121314151617181920212223242526272829303132333435&lt;configuration&gt;&lt;!-- 设置默认使用的文件系统 Hadoop支持file、HDFS、GFS、ali|Amazon云等文件系统 --&gt;&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://node1:8020&lt;/value&gt;&lt;/property&gt;&lt;!-- 设置Hadoop本地保存数据路径 --&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/export/data/hadoop-3.3.0&lt;/value&gt;&lt;/property&gt;&lt;!-- 设置HDFS web UI用户身份 --&gt;&lt;property&gt; &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt; &lt;value&gt;root&lt;/value&gt;&lt;/property&gt;&lt;!-- 整合hive 用户代理设置 --&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;!-- 文件系统垃圾桶保存时间 单位：分 --&gt;&lt;property&gt; &lt;name&gt;fs.trash.interval&lt;/name&gt; &lt;value&gt;1440&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; 3.hdfs-site.xml 1234567&lt;configuration&gt;&lt;!-- 设置SNN进程运行机器位置信息 --&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;node2:9868&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; 4.mapred-site.xml 12345678910111213141516171819202122232425262728293031323334&lt;configuration&gt;&lt;!-- 设置MR程序默认运行模式： yarn集群模式 local本地模式 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;&lt;!-- MR程序历史服务器端地址 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;node1:10020&lt;/value&gt;&lt;/property&gt;&lt;!-- 历史服务器web端地址 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;node1:19888&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;mapreduce.map.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;mapreduce.reduce.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; 5.yarn-site.xml 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;configuration&gt;&lt;!-- 设置YARN集群主角色运行机器位置 --&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;node1&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;!-- 是否将对容器实施物理内存限制 --&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;!-- 是否将对容器实施虚拟内存限制。 --&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;!-- 开启日志聚集 --&gt;&lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;!-- 设置yarn历史服务器地址 --&gt;&lt;property&gt; &lt;name&gt;yarn.log.server.url&lt;/name&gt; &lt;value&gt;http://node1:19888/jobhistory/logs&lt;/value&gt;&lt;/property&gt;&lt;!-- 日志保存的时间 7天 --&gt;&lt;property&gt; &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; &lt;value&gt;604800&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; (3)将hadoop添加到环境变量(三台) 1234vi /etc/profile#HADOOP_HOMEexport HADOOP_HOME=/export/server/hadoop-3.3.0export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 重新加载环境变量： 1source /etc/profile (4)向node2、3 分发hadoop目录 12scp -r /export/server/hadoop-3.3.0/ root@node2:/export/server/hadoop-3.3.0/scp -r /export/server/hadoop-3.3.0/ root@node3:/export/server/hadoop-3.3.0/ (5)在node1格式化hdfs 1hdfs namenode -format (6)启动hadoop集群 12start-dfs.shstart-yarn.sh （7）jps查看进程：[root@node2 ~]# jps5697 Jps4867 DataNode2183 QuorumPeerMain5065 NodeManager4973 SecondaryNameNodeWeb UI页面验证：yarn: http:&#x2F;&#x2F;主节点ip:9868&#x2F;hdfs: http:&#x2F;&#x2F;主节点ip:8088&#x2F;More info: Deployment 四、Zookeeper集群安装（1）上传、解压、安装zookeeper 1tar -zxvf /export/servers/zookeeper-3.4.6.tar.gr -C /export/servers/ 建立软连接 1ln -s zookeeper/zookeeper-3.4.6 （2）修改配置文件1.zoo.cfg 1234cd /export/server/zookeeper/conf/cp zoo_sample.cfg zoo.cfg #修改文件名mkdir -p /export/server/zookeeper/zkdatas/vim zoo.cfg 修改如下： 12345678910#Zookeeper的数据存放目录dataDir=/export/server/zookeeper/zkdatas# 保留多少个快照autopurge.snapRetainCount=3# 日志多少小时清理一次autopurge.purgeInterval=1# 集群中服务器地址server.1=node1:2888:3888server.2=node2:2888:3888server.3=node3:2888:3888 2.添加myid的配置在node1主机的&#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas&#x2F;这个路径下创建一个文件，文件名为myid ,文件内容为1 12mkdir -p /export/server/zookeeper/zkdatas/echo 1 &gt; /export/server/zookeeper/zkdatas/myid 分发myid 123cd /export/server/scp -r /export/server/zookeeper-3.4.6/ node2:$PWD scp -r /export/server/zookeeper-3.4.6/ node3:$PWD 3.在node2,node3修改myid的值，并建立软连接node2： 123cd /export/server/ln -s zookeeper-3.4.6/ zookeeper echo 2 &gt; /export/server/zookeeper/zkdatas/myid #node2 myid值为2 node3： 123cd /export/server/ln -s zookeeper-3.4.6/ zookeeper echo 3 &gt; /export/server/zookeeper/zkdatas/myid #node3 myid值为3 (3)添加环境变量(三台)： 1234vi /etc/profile#ZOOKEEPER_HOMEexport ZOOKEEPER_HOME=/export/server/zookeeperexport PATH=$PATH:$ZOOKEEPER_HOME/bin 重新加载环境变量： 1source /etc/profile （4）启动zookeeper（三台） 12/export/server/zookeeper/bin/zkServer.sh start #启动 /export/server/zookeeper/bin/zkServer.sh status #查看启动状态","categories":[],"tags":[]}],"categories":[],"tags":[]}